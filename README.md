## Setup Guide
*create a virtual environment*
git clone https://github.com/raisulislam0/10_min_school_rag.git

pip install -r requirements.txt

streamlit run stream.py
or
python -m streamlit run stream.py

Enter your query

## Tools, Library, Package

1. streamlit (python UI library)
2. easyocr (character reading from pdf)
3. poppler (PDF renderer)
4. pdf2image
5. numpy
6. os (python built-in os module)
7. re (Regex for text cleaning)
8. chromadb (vector database)
9. langchain (for chunking)
10. einops
11. ollama (llama3.2)
12. requests
13. sentence-transformers (for embedding model nomic-ai/nomic-embed-text-v2-moe)

## Sample Queries and Outputs

Q: বিয়ের সময় কল্যাণীর প্রকৃত বয়স কত ছিল?
Output: বিয়ের সময় কল্যাণীর প্রকৃত বয়স ১৫ ছিল।

Q: অপরিচিতা কবে কোথায় প্রথম প্রকাশিত হয়?
Output: ১৩২১ বঙ্গাব্দের ১৯১৪ কার্তিক সংখ্যায় / এটি প্রথম গ্রন্থভুক্ত হয় রবীন্দ্রগল্পের সংকলন গল্পসপ্তক'-এ

Q:কাকে অনুপমের ভাগ্য দেবতা বলে উল্লেখ করা হয়েছে?
Output: অনুপমের ভাগ্য দেবতা সেই নির্বিকার ব্যক্তিত্ব শম্ভুনাথ সেনের

Q:রবীন্দ্রনাথের কাব্যগ্রন্থগুলো কী কী?
Output: মানসী, সোনার তরী; চিত্রা; চৈতালি ক্ষণিকা নৈবেদ্য গীতাঞ্জলি বলাকা; পূরবী পুনশ্চ বিচিত্রা; সেঁজুতি জন্মদিনে শেষ লেখা প্রভৃতি |

Q:অপরিচিতা was first published in which year and where ?
Output:"অপরিচিতা" গল্পটি প্রথম প্রকাশিত হয়েছিল ১৯১৪ সালের কার্তিক সংখ্যায় 'সবুজপত্র' মাসিক পত্রিকায়।

Q:When did Rabindranath win nobel prize?
Output:Rabindranath won the Nobel Prize in Literature in 1913.

Q:  what is the main theme of অপরিচিতা ?
Output: অপরিচিতার মূল বিষয়বস্তু নারী-পুরুষের সম্মিলিত প্রতিরোধের কথা।

## Answer to the Questions:

  1. Initially, I tried pdfloader from langchain and pymupdf and several other pdf processor; however, they all failed extract bangla texts. Finally, I decided to use easyocr, poppler, einops, and numpy to extract bangla texts from the given pdf. This is it worked and I got almost a clean txt output using reader.py script. Later, the txt data was cleaned to removed unwanted pages and gibberish texts along with unwanted brackets and parenthesis generated by the pdf to text conversion.

  2. I used recursive character text splitter from langchain. I followed this strategy because it tris to chunk using paragraph within the limit, then newline, then other delimiters. This strategy can retain the context in each chunk which can yield better context retrieval.

  3. I used nomic-ai/nomic-embed-text-v2-moe since it was trained on 100+ different languages and yielded much better result compared to other fine-tuned models i found on huggingface and ollama. It uses Mixture of Experts (MoE): a neural network architecture to improve model efficiency and scalability by selecting specialized experts for different tasks. It was trained on around 2.5 million bangla pairs.

  4. I chose chromadb for its simplicity and prior experience with it. It use l2 (euclidean) distance for similarity search by default. I tried cosine, dot product, and l2 all three methods. However, I found no significant differnce in the output. Finally, I kept cosine similary. It is important to note that to detect vague and missing context in query cosine similarity gives the best result. Chromadb persistant client is used, which is utilize sqlite3 for storage. "chroma_bn" folder contains the storage.

  5.  The similarity threshold is set to 0.4. If retrieved chunk is below that then it would be discarded. If no chunk is found due to not maintaining the threshold then the chat bot would response with "দুঃখিত, আপনার প্রশ্নের জন্য পর্যাপ্ত প্রাসঙ্গিক তথ্য পাওয়া যায়নি।"

  6.  Without extract the text from pdf if I just upload the pdf to chatgpt, grok, or claude, even they failed to parse the pdf properly. Thus I used OCR to text the pdf texts. After extraction when I gave the text input chatgpt, grok, and claude they all could answer the questions perfectly regardless of complexity. However, I completed the task using ollama llama3.2 on my local machine. Due to its smaller size it fails to answer complicated questions. Not only the generation model but also embedding model has its limitation. Better fine-tuned bangla embedding model would gave much better result by providing the most relevant chunks to the model. If I change the num_ctx of llama3.2 to provide the full txt to the model it fails and hallucinate. Therefore, the issue lies in the generation model as well as the embedding model since grok and chatgpt with the full cleaned extracted text can generated perfect result.






